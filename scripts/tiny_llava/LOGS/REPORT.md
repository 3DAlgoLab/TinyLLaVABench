# 1. 数据对模型效果的影响
我们训练了v1和v1.1的版本，主要的区别就是v1版本使用的是LLaVA-1.5提供的数据，而v1.1版本使用的是ShareGPT4V的数据
而使用ShareGPT4V数据的质量优于LLaVA-1.5，也因此有了更好的效果

# 2. 中间的连接器对模型效果的影响
我们尝试了MLP和Resampler两种方式，该部分主要比较两种方式的实现与对应的效果

# 3. 微调模型不同部分对模型效果的影响
这部分主要探究：是否打开CLIP训练， LoRA该微调哪些层，打开LLM是全量还是微调特定层（如MLP），描述该部分的消融实验

# 4. 可能有时间探究，可能没有时间探究
如果有时间，探究MoE和动态调整visual token的数量
